{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f07458b0",
   "metadata": {},
   "source": [
    "# CS 585 - Homework 4\n",
    "Tania Soutonglang A20439949"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b7463ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycrfsuite\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed5ca23",
   "metadata": {},
   "source": [
    "## Problem 1 - Reading the Data in ConLL Format\n",
    "\n",
    "- Write a function that reads a .tsv files in the CoNLL format and returns two “list of lists” as output:\n",
    "    - A list of sequences of tokens, where a single token may be a word or punctuation.\n",
    "    - A list of sequences of tags, representing token-level annotation. You should see these 3 tags in your data (“B-Disease”, “I-Disease”, “O”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a1bf0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tsv_CoNLL(file_path):\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        current_tokens = []\n",
    "        current_tags = []\n",
    "        \n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                if current_tokens and current_tags:\n",
    "                    tokens.append(current_tokens)\n",
    "                    tags.append(current_tags)\n",
    "                current_tokens = []\n",
    "                current_tags = []\n",
    "            else:\n",
    "                parts = line.split('\\t')\n",
    "                if len(parts) == 2:\n",
    "                    token, tag = parts\n",
    "                    current_tokens.append(token)\n",
    "                    current_tags.append(tag)\n",
    "    \n",
    "    return tokens, tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55caea08",
   "metadata": {},
   "source": [
    "- Apply your function to train.tsv and test.tsv. To show you have read in the data correctly, show the following in your notebook output:\n",
    "    - The number of sequences in train and test. (You should see 5432 sequences in train and 940 sequences in test.)\n",
    "    - The tokens and tags of the first sequence in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76ebe5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training sequences:  5432\n",
      "testing sequences:  940\n"
     ]
    }
   ],
   "source": [
    "train_sents, train_tags = read_tsv_CoNLL(\"train.tsv\")\n",
    "test_sents, test_tags = read_tsv_CoNLL(\"test.tsv\")\n",
    "\n",
    "print(\"training sequences: \", len(train_sents))\n",
    "print(\"testing sequences: \", len(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d97cfbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Identification', 'of', 'APC2', ',', 'a', 'homologue', 'of', 'the', 'adenomatous', 'polyposis', 'coli', 'tumour', 'suppressor', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Disease', 'I-Disease', 'I-Disease', 'I-Disease', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(train_sents[0])\n",
    "print(train_tags[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fdd825",
   "metadata": {},
   "source": [
    "## Problem 2 - Data Discovery\n",
    "In this problem you will examine the data that you read into memory in the previous problem. Using the training dataset for analysis, show the following in your notebook output:\n",
    "- The count of each of the 3 tags in the training data: “B-Disease”, “I-Disease”, and “O”. Note that the most frequent token is \"O\", since most words are not part of a disease mention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d218838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'O': 27, 'I-Disease': 3, 'B-Disease': 2})\n"
     ]
    }
   ],
   "source": [
    "tag_counts = {}\n",
    "\n",
    "for sequence in train_tags:\n",
    "    tag_counts = Counter(sequence)\n",
    "    \n",
    "print(tag_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732df44b",
   "metadata": {},
   "source": [
    "- The 20 most common words/tokens that appear with the tags “B-Disease” or “I-Disease”. That is, show words that often appear disease mentions. (You may show frequent “B-Disease” and “I-Disease” words separately, or you may combine them into a single list.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69b7c981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('-', 636),\n",
       " ('deficiency', 322),\n",
       " ('syndrome', 281),\n",
       " ('cancer', 269),\n",
       " ('disease', 256),\n",
       " ('of', 178),\n",
       " ('dystrophy', 176),\n",
       " ('breast', 151),\n",
       " ('ovarian', 132),\n",
       " ('X', 122),\n",
       " ('and', 120),\n",
       " ('DM', 120),\n",
       " ('ALD', 114),\n",
       " ('DMD', 110),\n",
       " ('APC', 100),\n",
       " ('disorder', 94),\n",
       " ('muscular', 94),\n",
       " ('G6PD', 92),\n",
       " ('linked', 81),\n",
       " ('the', 78)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of words for \"B-Disease\" or \"I-Disease\" tags\n",
    "disease_words = [word for i, \n",
    "                 seq in enumerate(train_sents) for j, \n",
    "                 word in enumerate(seq) \n",
    "                 if train_tags[i][j] in [\"B-Disease\", \"I-Disease\"]]\n",
    "\n",
    "word_counts = Counter(disease_words)\n",
    "\n",
    "# get the 20 most common words\n",
    "word_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7188dd",
   "metadata": {},
   "source": [
    "Review the list of words that commonly appear in disease mentions. Do you see any patterns? (You do not need to answer in writing, but it may be helpful in Problem 3 where you design a feature.) \n",
    "\n",
    "The most common words in the top 20 relate to cancer, and after that there are a lot of abbreviations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5aebed",
   "metadata": {},
   "source": [
    "## Problem 3 - Building Features\n",
    "In this problem, you will build the features that you will use in your CRF model.\n",
    "\n",
    "- Write a function that takes two inputs:\n",
    "    - A sequence of tokens\n",
    "    - An integer position, pointing to one token in that sequence\n",
    "    \n",
    "    and returns a list of features, represented as a list of strings. At minimum, include these features:\n",
    "    \n",
    "    - The current word/token in lower case\n",
    "    - The suffix (last 3 characters) of the current word\n",
    "    - The previous word/token (position i-1) or “BOS” if at the beginning of the sequence\n",
    "    - The next word/token (position i+1), or “EOS” if at the beginning of the sequence\n",
    "    - At least one other feature of your choice\n",
    "    \n",
    "this function was primarily taken from the section 19 notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fb405d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i]\n",
    "    # get features\n",
    "    features = [\n",
    "        'word.lower=' + word.lower(),     # lower-case of word\n",
    "        'word.suffix=' + word[-3:],       # suffix of word\n",
    "        'word.prefix=' + word[:3].lower(),        # prefix of word\n",
    "    ]\n",
    "    \n",
    "    # get prev word\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    # get next word\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9833bbe0",
   "metadata": {},
   "source": [
    "- Apply your function your train and test token sequences (from output of Problem 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6fbe87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = train_tags\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = test_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58aa3ff",
   "metadata": {},
   "source": [
    "- To show that you have completed this step, apply your output to the first 3 words in the first sequence of the training set. Your output should look something like this (note the names and order of your features in your notebook do not need to match this output):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e741118a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word.lower=identification', 'word.suffix=ion', 'word.prefix=ide', 'BOS', '+1:word.lower=o']\n",
      "['word.lower=of', 'word.suffix=of', 'word.prefix=of', '-1:word.lower=i', '+1:word.lower=a']\n",
      "['word.lower=apc2', 'word.suffix=PC2', 'word.prefix=apc', '-1:word.lower=o', '+1:word.lower=,']\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(X_train[0][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaa3224",
   "metadata": {},
   "source": [
    "## Problem 4 - Training a CRF Model\n",
    "In this problem, you will train a CRF model and evaluate it using metrics computed over individual tags.\n",
    "\n",
    "- Using the python-crfsuite library, train a CRF sequential tagging model using feature sequences that you built in the previous step. Using your training data as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "749a33de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create pycrgsuite.Trainer\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for X_seq, y_seq in zip(X_train, y_train):\n",
    "    trainer.append(X_seq, y_seq)\n",
    "    \n",
    "# set the parameters\n",
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': False\n",
    "})\n",
    "\n",
    "# possible parameters\n",
    "trainer.params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfa9b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "trainer.train('conll2002-esp.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de384ae3",
   "metadata": {},
   "source": [
    "- Apply your model to your test dataset to generate predicted tag sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f4e4ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x1a9d566ec10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('conll2002-esp.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b174f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [tagger.tag(sent) for sent in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dcec21",
   "metadata": {},
   "source": [
    "- For each of the 3 labels (\"B-Disease\", \"I-Disease\", and “O\") show precision, recall, f1-score. (You may use the sckit-learn function classification_report to complete this step. You may also want to “flatten” both the true and predicted tags into a single list of tags to apply this function.)\n",
    "\n",
    "taken from the section 19 notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fb06557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bio_classification_report(y_true, y_pred):\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_)\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73bb4ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   B-Disease       0.83      0.71      0.77       960\n",
      "   I-Disease       0.81      0.75      0.78      1087\n",
      "           O       0.98      0.99      0.98     22450\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     24497\n",
      "   macro avg       0.87      0.82      0.84     24497\n",
      "weighted avg       0.97      0.97      0.97     24497\n",
      " samples avg       0.97      0.97      0.97     24497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bio_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3cd8be",
   "metadata": {},
   "source": [
    "## Problem 5 - Inspecting the Trained Model\n",
    "In this problem you will examine parameter weights assigned by your model. You can do this by calling “tagger.info().transitions” and “tagger.info().state_features” on your trained model object.\n",
    "\n",
    "- In your notebook, show parameter weights given to transitions between the 3 tag types (\"BDisease\", \"I-Disease\", and \"O\").\n",
    "\n",
    "Taken from section 19 notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e558e837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "B-Disease ->\t I-Disease \t4.40949\n",
      "O      ->\t O       \t3.54461\n",
      "O      ->\t B-Disease \t3.52636\n",
      "I-Disease ->\t I-Disease \t3.30651\n",
      "B-Disease ->\t O       \t-2.30715\n",
      "\n",
      "Top unlikely transitions:\n",
      "I-Disease ->\t I-Disease \t3.30651\n",
      "B-Disease ->\t O       \t-2.30715\n",
      "I-Disease ->\t O       \t-3.70075\n",
      "I-Disease ->\t B-Disease \t-3.97391\n",
      "B-Disease ->\t B-Disease \t-4.82345\n"
     ]
    }
   ],
   "source": [
    "transitions = tagger.info().transitions\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s ->\\t %-7s \\t%0.5f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(transitions).most_common(5))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(transitions).most_common()[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9063ed",
   "metadata": {},
   "source": [
    "- Refer back to the feature you designed in Problem 3 (the feature \"of your choice\"). Show the parameter weights assigned to this feature. You may truncate this list if it is very long. (This may happen if you included a word from the sequence in the feature name, so your feature was expanded to become a larger set of features that grows with your vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b079ae37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "7.226251 B-Disease \tword.prefix=ank\n",
      "6.340155 B-Disease \tword.prefix=obe\n",
      "4.873239 B-Disease \tword.prefix=goi\n",
      "4.865676 B-Disease \tword.prefix=edm\n",
      "4.616451 B-Disease \tword.prefix=pie\n",
      "4.411290 O      \tword.prefix=mut\n",
      "3.878427 B-Disease \tword.prefix=ado\n",
      "3.492262 O      \tword.prefix=wit\n",
      "3.342234 O      \tword.prefix=bio\n",
      "3.341892 O      \tword.prefix=cas\n",
      "\n",
      "Top negative:\n",
      "-2.478031 O      \tword.prefix=dea\n",
      "-2.484928 O      \tword.prefix=duc\n",
      "-2.738019 O      \tword.prefix=hyp\n",
      "-2.826305 O      \tword.prefix=ost\n",
      "-2.861462 O      \tword.prefix=elb\n",
      "-3.022407 O      \tword.prefix=neo\n",
      "-3.227033 O      \tword.prefix=pit\n",
      "-3.270224 O      \tword.prefix=ane\n",
      "-3.580120 O      \tword.prefix=dys\n",
      "-4.465175 O      \tword.prefix=tum\n"
     ]
    }
   ],
   "source": [
    "state_features = tagger.info().state_features\n",
    "\n",
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-6s \\t%s\" % (weight, label, attr))\n",
    "        \n",
    "features = list(tagger.info().state_features.keys())\n",
    "prefix_feat = {}\n",
    "for feat, tag in features:\n",
    "    if 'word.prefix' == feat.split(\"=\")[0]:\n",
    "        prefix_feat[feat, tag] = state_features[feat, tag]\n",
    "    \n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(prefix_feat).most_common(10))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(prefix_feat).most_common()[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831ac883",
   "metadata": {},
   "source": [
    "## Problem 6 - Document Level Performance\n",
    "Tag-level accuracy is easy to compute, but it is not very easy to understand. In particular, one disease reference may cover both \"B-Disease\" and \"I-Disease\" tokens. To give another view of model performance, compute document-level precision and recall on your experiment output. To do this:\n",
    "- Write a function that aggregates token-level tags to a document-level label. For example, convert a tag sequence like (\"O\", \"B-Disease\", \"I-Disease\", \"O\", \"O\") to a single label y=1. Your function should assign y=1 to a sequence with one or more disease mentions (at least one \"BDisease\" tag) and y=0 to a sequence with no disease mentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c291d10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_to_document_level(tags):\n",
    "    # check if there's at least one disease tag in the tag sequence\n",
    "    if \"B-Disease\" or \"I-Disease\" in tags:\n",
    "        return 1  # Document contains disease mention(s)\n",
    "    else:\n",
    "        return 0  # Document does not contain disease mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ccfc8f",
   "metadata": {},
   "source": [
    "- Apply your function to both true and predicted document-level labels from your test set. Use the output to compute document level precision and recall of your model. Show your results in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c2ce83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to both true and predicted document-level labels\n",
    "y_doc = [aggregate_to_document_level(tags) for tags in y_test]\n",
    "y_doc_pred = [aggregate_to_document_level(tags) for tags in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86156759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document-level Precision: 1.0\n",
      "Document-level Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "document_precision = precision_score(y_doc, y_doc_pred)\n",
    "document_recall = recall_score(y_doc, y_doc_pred)\n",
    "\n",
    "print(\"Document-level Precision:\", document_precision)\n",
    "print(\"Document-level Recall:\", document_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2bf4f9",
   "metadata": {},
   "source": [
    "## Problem 7 - State Transitions\n",
    "The python-crfsuite library allows you to set a Boolean hyper-parameter called “feature.possible_transitions”. If this parameter is True, then the model may output tag-to-tag transitions that were never seen in training data. (You do not need to apply this parameter in your code to answer this question)\n",
    "\n",
    "- What is an example of one tag-to-tag transition that never occurred in the training data?\n",
    "\n",
    "O to I-Disease and I-Disease to O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee30c68",
   "metadata": {},
   "source": [
    "- For this particular experiment, do you think it makes sense to set this parameter to True or False? That is, should you allow transitions that never occurred in the training data? Explain your answer briefly.\n",
    "\n",
    "For this dataset it would be okay to set the parameter to True because it is smaller and does not have as many transition combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ff6ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
