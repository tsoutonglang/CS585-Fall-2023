{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f07458b0",
   "metadata": {},
   "source": [
    "# CS 585 - Homework 4\n",
    "Tania Soutonglang A20439949"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b7463ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycrfsuite\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed5ca23",
   "metadata": {},
   "source": [
    "## Problem 1 - Reading the Data in ConLL Format\n",
    "\n",
    "- Write a function that reads a .tsv files in the CoNLL format and returns two “list of lists” as output:\n",
    "    - A list of sequences of tokens, where a single token may be a word or punctuation.\n",
    "    - A list of sequences of tags, representing token-level annotation. You should see these 3 tags in your data (“B-Disease”, “I-Disease”, “O”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a1bf0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tsv_CoNLL(file_path):\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        current_tokens = []\n",
    "        current_tags = []\n",
    "        \n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                if current_tokens and current_tags:\n",
    "                    tokens.append(current_tokens)\n",
    "                    tags.append(current_tags)\n",
    "                current_tokens = []\n",
    "                current_tags = []\n",
    "            else:\n",
    "                parts = line.split('\\t')\n",
    "                if len(parts) == 2:\n",
    "                    token, tag = parts\n",
    "                    current_tokens.append(token)\n",
    "                    current_tags.append(tag)\n",
    "    \n",
    "    return tokens, tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55caea08",
   "metadata": {},
   "source": [
    "- Apply your function to train.tsv and test.tsv. To show you have read in the data correctly, show the following in your notebook output:\n",
    "    - The number of sequences in train and test. (You should see 5432 sequences in train and 940 sequences in test.)\n",
    "    - The tokens and tags of the first sequence in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76ebe5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training sequences:  5432\n",
      "testing sequences:  940\n"
     ]
    }
   ],
   "source": [
    "train_tokens, train_tags = read_tsv_CoNLL(\"train.tsv\")\n",
    "test_tokens, test_tags = read_tsv_CoNLL(\"test.tsv\")\n",
    "\n",
    "print(\"training sequences: \", len(train_tokens))\n",
    "print(\"testing sequences: \", len(test_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d97cfbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Identification', 'of', 'APC2', ',', 'a', 'homologue', 'of', 'the', 'adenomatous', 'polyposis', 'coli', 'tumour', 'suppressor', '.']\n",
      "['Identification', 'of', 'APC2', ',', 'a', 'homologue', 'of', 'the', 'adenomatous', 'polyposis', 'coli', 'tumour', 'suppressor', '.']\n"
     ]
    }
   ],
   "source": [
    "print(train_tokens[0])\n",
    "print(train_tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fdd825",
   "metadata": {},
   "source": [
    "## Problem 2 - Data Discovery\n",
    "In this problem you will examine the data that you read into memory in the previous problem. Using the training dataset for analysis, show the following in your notebook output:\n",
    "- The count of each of the 3 tags in the training data: “B-Disease”, “I-Disease”, and “O”. Note that the most frequent token is \"O\", since most words are not part of a disease mention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d218838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'O': 27, 'I-Disease': 3, 'B-Disease': 2})\n"
     ]
    }
   ],
   "source": [
    "tag_counts = {}\n",
    "\n",
    "for sequence in train_tags:\n",
    "    tag_counts = Counter(sequence)\n",
    "    \n",
    "print(tag_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732df44b",
   "metadata": {},
   "source": [
    "- The 20 most common words/tokens that appear with the tags “B-Disease” or “I-Disease”. That is, show words that often appear disease mentions. (You may show frequent “B-Disease” and “I-Disease” words separately, or you may combine them into a single list.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69b7c981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('-', 636),\n",
       " ('deficiency', 322),\n",
       " ('syndrome', 281),\n",
       " ('cancer', 269),\n",
       " ('disease', 256),\n",
       " ('of', 178),\n",
       " ('dystrophy', 176),\n",
       " ('breast', 151),\n",
       " ('ovarian', 132),\n",
       " ('X', 122),\n",
       " ('and', 120),\n",
       " ('DM', 120),\n",
       " ('ALD', 114),\n",
       " ('DMD', 110),\n",
       " ('APC', 100),\n",
       " ('disorder', 94),\n",
       " ('muscular', 94),\n",
       " ('G6PD', 92),\n",
       " ('linked', 81),\n",
       " ('the', 78)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of words for \"B-Disease\" or \"I-Disease\" tags\n",
    "disease_words = [word for i, \n",
    "                 seq in enumerate(train_tokens) for j, \n",
    "                 word in enumerate(seq) \n",
    "                 if train_tags[i][j] in [\"B-Disease\", \"I-Disease\"]]\n",
    "\n",
    "word_counts = Counter(disease_words)\n",
    "\n",
    "# get the 20 most common words\n",
    "word_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7188dd",
   "metadata": {},
   "source": [
    "Review the list of words that commonly appear in disease mentions. Do you see any patterns? (You do not need to answer in writing, but it may be helpful in Problem 3 where you design a feature.) \n",
    "\n",
    "The most common words in the top 20 relate to cancer, and after that there are a lot of abbreviations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5aebed",
   "metadata": {},
   "source": [
    "## Problem 3 - Building Features\n",
    "In this problem, you will build the features that you will use in your CRF model.\n",
    "\n",
    "- Write a function that takes two inputs:\n",
    "    - A sequence of tokens\n",
    "    - An integer position, pointing to one token in that sequence\n",
    "    \n",
    "    and returns a list of features, represented as a list of strings. At minimum, include these features:\n",
    "    \n",
    "    - The current word/token in lower case\n",
    "    - The suffix (last 3 characters) of the current word\n",
    "    - The previous word/token (position i-1) or “BOS” if at the beginning of the sequence\n",
    "    - The next word/token (position i+1), or “EOS” if at the beginning of the sequence\n",
    "    - At least one other feature of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e038721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sequence, i):\n",
    "    features = []\n",
    "    \n",
    "    # check that i is valid\n",
    "    if i >= len(sequence) or i < 0:\n",
    "        return features\n",
    "    \n",
    "    # current word in lower case\n",
    "    current_word = sequence[i].lower()\n",
    "    features.append(f'w.lower={current_word}'.format(current_word))\n",
    "    \n",
    "    # suffix\n",
    "    suffix = current_word[len(current_word)-3:]\n",
    "    features.append(f'w.suffix={suffix}'.format(suffix))\n",
    "    \n",
    "    # previous word\n",
    "    prev_word = \"\"\n",
    "    if i == 0:\n",
    "        prev_word = \"BOS\"\n",
    "        features.append(prev_word)\n",
    "    else:\n",
    "        prev_word = sequence[i-1]\n",
    "        features.append(prev_word)\n",
    "    \n",
    "    # next word\n",
    "    next_word = \"\"\n",
    "    if i == len(sequence)-1:\n",
    "        next_word = \"EOS\"\n",
    "        features.append(next_word)\n",
    "    else:\n",
    "        next_word = sequence[i+1]\n",
    "        features.append(next_word)\n",
    "        \n",
    "    # prefix - my choice\n",
    "    prefix = current_word[:3]\n",
    "    features.append(f'w.prefix={prefix}'.format(prefix))\n",
    "        \n",
    "    # length of current word - my choice\n",
    "    length = len(current_word)\n",
    "    features.append(f'w.length={length}'.format(length))\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9833bbe0",
   "metadata": {},
   "source": [
    "- Apply your function your train and test token sequences (from output of Problem 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24cddbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "\n",
    "for sequence in train_tokens:\n",
    "    seq = []\n",
    "    for i in range(len(sequence)):\n",
    "        features = word2features(sequence, i)\n",
    "        seq.append(features)\n",
    "    X_train.append(seq)\n",
    "\n",
    "y_train = train_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f434d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "\n",
    "for sequence in test_tokens:\n",
    "    seq = []\n",
    "    for i in range(len(sequence)):\n",
    "        features = word2features(sequence, i)\n",
    "        seq.append(features)\n",
    "    X_test.append(seq)\n",
    "        \n",
    "y_test = test_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58aa3ff",
   "metadata": {},
   "source": [
    "- To show that you have completed this step, apply your output to the first 3 words in the first sequence of the training set. Your output should look something like this (note the names and order of your features in your notebook do not need to match this output):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e741118a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features of first 3 words:\n",
      "['w.lower=identification', 'w.suffix=ion', 'BOS', 'of', 'w.prefix=ide', 'w.length=14']\n",
      "['w.lower=of', 'w.suffix=f', 'Identification', 'APC2', 'w.prefix=of', 'w.length=2']\n",
      "['w.lower=apc2', 'w.suffix=pc2', 'of', ',', 'w.prefix=apc', 'w.length=4']\n"
     ]
    }
   ],
   "source": [
    "print(\"Features of first 3 words:\")\n",
    "for i in range(3):\n",
    "    print(X_train[0][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaa3224",
   "metadata": {},
   "source": [
    "## Problem 4 - Training a CRF Model\n",
    "In this problem, you will train a CRF model and evaluate it using metrics computed over individual tags.\n",
    "\n",
    "- Using the python-crfsuite library, train a CRF sequential tagging model using feature sequences that you built in the previous step. Using your training data as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "749a33de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create pycrgsuite.Trainer\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for X_seq, y_seq in zip(X_train, y_train):\n",
    "    trainer.append(X_seq, y_seq)\n",
    "    \n",
    "# set the parameters\n",
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})\n",
    "\n",
    "# possible parameters\n",
    "trainer.params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfa9b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "trainer.train('conll2002-esp.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de384ae3",
   "metadata": {},
   "source": [
    "- Apply your model to your test dataset to generate predicted tag sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f4e4ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x2248b0576d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('conll2002-esp.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bae82be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w.lower=clustering',\n",
       " 'w.suffix=ing',\n",
       " 'BOS',\n",
       " 'of',\n",
       " 'w.prefix=clu',\n",
       " 'w.length=10']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d2e43bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering of missense mutations in the ataxia - telangiectasia gene in a sporadic T - cell leukaemia .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tagging a sentence to see how it works\n",
    "example_sent = test_tokens[0]\n",
    "print(' '.join(example_sent), end='\\n\\n')\n",
    "\n",
    "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "# print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c1dbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open(model)\n",
    "test_labels = []\n",
    "predicted_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd2f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for features in test_features:\n",
    "    predicted_labels.extend(tagger.tag(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dcec21",
   "metadata": {},
   "source": [
    "- For each of the 3 labels (\"B-Disease\", \"I-Disease\", and “O\") show precision, recall, f1-score. (You may use the sckit-learn function classification_report to complete this step. You may also want to “flatten” both the true and predicted tags into a single list of tags to apply this function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb06557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3cd8be",
   "metadata": {},
   "source": [
    "## Problem 5 - Inspecting the Trained Model\n",
    "In this problem you will examine parameter weights assigned by your model. You can do this by calling “tagger.info().transitions” and “tagger.info().state_features” on your trained model object.\n",
    "\n",
    "- In your notebook, show parameter weights given to transitions between the 3 tag types (\"BDisease\", \"I-Disease\", and \"O\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e558e837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d9063ed",
   "metadata": {},
   "source": [
    "- Refer back to the feature you designed in Problem 3 (the feature \"of your choice\"). Show the parameter weights assigned to this feature. You may truncate this list if it is very long. (This may happen if you included a word from the sequence in the feature name, so your feature was expanded to become a larger set of features that grows with your vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d45b3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5823b28c",
   "metadata": {},
   "source": [
    "- *IF* your feature was dropped during model training (that is, there is nothing to show in the previous step) then return to Problem 4 and design a new feature that is used in your model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831ac883",
   "metadata": {},
   "source": [
    "## Problem 6 - Document Level Performance\n",
    "Tag-level accuracy is easy to compute, but it is not very easy to understand. In particular, one disease reference may cover both \"B-Disease\" and \"I-Disease\" tokens. To give another view of model performance, compute document-level precision and recall on your experiment output. To do this:\n",
    "- Write a function that aggregates token-level tags to a document-level label. For example, convert a tag sequence like (\"O\", \"B-Disease\", \"I-Disease\", \"O\", \"O\") to a single label y=1. Your function should assign y=1 to a sequence with one or more disease mentions (at least one \"BDisease\" tag) and y=0 to a sequence with no disease mentions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ccfc8f",
   "metadata": {},
   "source": [
    "- Apply your function to both true and predicted document-level labels from your test set. Use the output to compute document level precision and recall of your model. Show your results in your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2bf4f9",
   "metadata": {},
   "source": [
    "## Problem 7 - State Transitions\n",
    "The python-crfsuite library allows you to set a Boolean hyper-parameter called “feature.possible_transitions”. If this parameter is True, then the model may output tag-to-tag transitions that were never seen in training data. (You do not need to apply this parameter in your code to answer this question)\n",
    "\n",
    "- What is an example of one tag-to-tag transition that never occurred in the training data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee30c68",
   "metadata": {},
   "source": [
    "- For this particular experiment, do you think it makes sense to set this parameter to True or False? That is, should you allow transitions that never occurred in the training data? Explain your answer briefly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ff6ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
