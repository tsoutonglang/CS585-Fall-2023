{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6aafbfa-2d87-4f34-91fc-6228d87954b9",
   "metadata": {},
   "source": [
    "# CS 585 - HW 1 - Getting Started\n",
    "\n",
    "Tania Soutonglang<br>\n",
    "A20439949"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cfbd0c8-48c1-4773-ad47-f0bf80f9b885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tsout\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#NLTK setup - uncomment and run first time you import NLTK\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from csv import QUOTE_NONE\n",
    "\n",
    "import numpy as np\n",
    "from nltk import probability\n",
    "import math\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada6ae7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contains no wit , only labored gags</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that loves its characters and communicates som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0       hide new secretions from the parental units       0\n",
       "1               contains no wit , only labored gags       0\n",
       "2  that loves its characters and communicates som...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import sst dataset\n",
    "df_sst = pd.read_csv(\"SST-2/train.tsv\",delimiter=\"\\t\")\n",
    "df_sst.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "894ae4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What came into force after the new constitutio...</td>\n",
       "      <td>As of that day, the new constitution heralding...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the first major city in the stream of ...</td>\n",
       "      <td>The most important tributaries in this area ar...</td>\n",
       "      <td>not_entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What is the minimum required if you want to te...</td>\n",
       "      <td>In most provinces a second Bachelor's Degree s...</td>\n",
       "      <td>not_entailment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           question  \\\n",
       "0      0  What came into force after the new constitutio...   \n",
       "1      1  What is the first major city in the stream of ...   \n",
       "2      2  What is the minimum required if you want to te...   \n",
       "\n",
       "                                            sentence           label  \n",
       "0  As of that day, the new constitution heralding...      entailment  \n",
       "1  The most important tributaries in this area ar...  not_entailment  \n",
       "2  In most provinces a second Bachelor's Degree s...  not_entailment  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import qnli dataset\n",
    "df_qnli = pd.read_csv(\"QNLI/dev.tsv\",delimiter=\"\\t\",quoting=QUOTE_NONE)\n",
    "df_qnli.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8676afd0",
   "metadata": {},
   "source": [
    "## Problem 1 - Representing English Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cea4e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         hide new secretions from the parental units \n",
       "1                 contains no wit , only labored gags \n",
       "2    that loves its characters and communicates som...\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create sst series with only sentence column\n",
    "df_sstData = df_sst[['sentence']].dropna()\n",
    "df_sstData = df_sstData['sentence'].str.lower()\n",
    "df_sstData.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6b8ce29-a936-4146-9d83-661495910398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    as of that day, the new constitution heralding...\n",
       "1    the most important tributaries in this area ar...\n",
       "2    in most provinces a second bachelor's degree s...\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create qnli series with only sentence column\n",
    "df_qnliData = df_qnli[['sentence']].dropna()\n",
    "df_qnliData = df_qnliData['sentence'].str.lower()\n",
    "df_qnliData.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f56ed85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "''\n",
      "'30s\n",
      "'40s\n",
      "'50s\n",
      "'53\n",
      "'60s\n",
      "'70s\n",
      "'80s\n",
      "'90s\n",
      "'d\n"
     ]
    }
   ],
   "source": [
    "sst_tokens = []\n",
    "\n",
    "# create token list for sst data\n",
    "for sentence in df_sstData:\n",
    "    # tokenize the sentence\n",
    "    tokens = word_tokenize(sentence)\n",
    "\n",
    "    # filter out the punctuation\n",
    "    filtered_tokens = [token for token in tokens if token not in string.punctuation]\n",
    "\n",
    "    # append tokens to list\n",
    "    sst_tokens.append(filtered_tokens)\n",
    "\n",
    "temp = []\n",
    "for words in sst_tokens:\n",
    "    temp.extend(words)\n",
    "sst_vocab = np.unique(temp)\n",
    "\n",
    "for token in range(10):\n",
    "    print(sst_vocab[token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de60e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "''\n",
      "'aided\n",
      "'apothecary\n",
      "'bath\n",
      "'bends\n",
      "'bucks\n",
      "'carry\n",
      "'chares\n",
      "'church\n",
      "'comb\n"
     ]
    }
   ],
   "source": [
    "qnli_tokens = []\n",
    "\n",
    "# create token list for qnli data\n",
    "for sentence in df_qnliData:\n",
    "    # tokenize the sentence\n",
    "    tokens = word_tokenize(sentence)\n",
    "\n",
    "    # filter out the punctuation\n",
    "    filtered_tokens = [token for token in tokens if token not in string.punctuation]\n",
    "\n",
    "    # append tokens to list\n",
    "    qnli_tokens.append(filtered_tokens)\n",
    "\n",
    "temp = []\n",
    "for words in qnli_tokens:\n",
    "    temp.extend(words)\n",
    "qnli_vocab = np.unique(temp)\n",
    "\n",
    "for token in range(10):\n",
    "    print(qnli_vocab[token])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483091c2",
   "metadata": {},
   "source": [
    "## Problem 2 - Word Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c7f58b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_probDist(tokenList):\n",
    "    # get the total number of tokens\n",
    "    count = len(tokenList)\n",
    "\n",
    "    # create a frequency distribution of the token list\n",
    "    freqDist = probability.FreqDist(tokenList)\n",
    "\n",
    "    # calculate the probability of each token\n",
    "    probDist = {token: freq / count for token, freq in freqDist.items()}\n",
    "\n",
    "    return probDist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f1aa2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999999999999606\n"
     ]
    }
   ],
   "source": [
    "sst_probDist = create_probDist(sst_vocab)\n",
    "print(sum(sst_probDist.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "445e6de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000001854\n"
     ]
    }
   ],
   "source": [
    "qnli_probDist = create_probDist(qnli_vocab)\n",
    "print(sum(qnli_probDist.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb08223",
   "metadata": {},
   "source": [
    "## Problem 3 - Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "904c843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(probDist):\n",
    "    entropy = 0.0\n",
    "\n",
    "    # calculate the entropy of each word\n",
    "    for prob in probDist.values():\n",
    "        if prob > 0:\n",
    "            entropy += -prob * math.log2(prob)\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "147bc426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.851944197996536\n"
     ]
    }
   ],
   "source": [
    "sst_entropy = calc_entropy(sst_probDist)\n",
    "print(sst_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c5e93a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.944071453008073\n"
     ]
    }
   ],
   "source": [
    "qnli_entropy = calc_entropy(qnli_probDist)\n",
    "print(qnli_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79b0ec5",
   "metadata": {},
   "source": [
    "## Problem 4 - KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0812bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_KLDivergence(probDist_a, probDist_b):\n",
    "    kl_divergence = 0.0\n",
    "\n",
    "    for key, prob_a in probDist_a.items():\n",
    "        # Get the corresponding probability from the 2nd list, otherwise default to 0 if it doesn't exist\n",
    "        prob_b = probDist_b.get(key, 0)\n",
    "\n",
    "        # calculate the KL divergence\n",
    "        if prob_b > 0:\n",
    "            kl_divergence += prob_a * math.log2(prob_a / prob_b)\n",
    "\n",
    "    return kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d1f4a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.032000918551245115\n"
     ]
    }
   ],
   "source": [
    "sst_KLqnli = calc_KLDivergence(sst_probDist, qnli_probDist)\n",
    "print(sst_KLqnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0aa0f008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.030021291903982113\n"
     ]
    }
   ],
   "source": [
    "qnli_KLsst = calc_KLDivergence(qnli_probDist, sst_probDist)\n",
    "print(qnli_KLsst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b7c5b6",
   "metadata": {},
   "source": [
    "## Problem 5 - Entropy Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a12aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_perWordEntropyRate(doc, probDist):\n",
    "    # split the inputted document into tokens \n",
    "    tokens = doc.split()\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    token_count = len(words)\n",
    "    \n",
    "    entropy_rate = 0.0\n",
    "\n",
    "    for word in tokens:\n",
    "        # get the probability of the word, otherwise it will be 0\n",
    "        probability = probDist.get(word, 0)\n",
    "        if probability > 0:\n",
    "            entropy_rate += -probability * math.log2(probability)\n",
    "\n",
    "        # find the per-word rate\n",
    "        if token_count > 0:\n",
    "            entropy_rate /= token_count\n",
    "\n",
    "    return entropy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a36a68c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie review of The Nun II from Rotten Tomatoes (https://www.rottentomatoes.com/m/the_nun_ii/reviews)\n",
    "review = \"A narratively bland sequel that grants star Taissa Farmiga a bit more agency (while wasting Storm Reid), The Nun II proves that while there's plenty of box office in The Conjuring Universe, the storytelling techniques are phoning it in.\"\n",
    "review = review.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "166d5283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.674733438334197e-06\n"
     ]
    }
   ],
   "source": [
    "# per-word entropy using sst probability distribution\n",
    "sst_perWord = calc_perWordEntropyRate(review, sst_probDist)\n",
    "print(sst_perWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b26c7f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.470284171075425e-06\n"
     ]
    }
   ],
   "source": [
    "# per-word entropy using qnli probability distribution\n",
    "qnli_perWord = calc_perWordEntropyRate(review, qnli_probDist)\n",
    "print(qnli_perWord)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
